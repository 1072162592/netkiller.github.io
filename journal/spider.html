<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Python Spider 爬虫实例</title><link rel="stylesheet" type="text/css" href="docbook.css"/><link rel="stylesheet" type="text/css" href="/journal/journal.css"/><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"/><meta name="description" content="."/><meta name="keywords" content="spider, , "/><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69658182-1', 'auto');
  ga('send', 'pageview');

</script></head><body><a xmlns="" href="http://www.netkiller.cn/">Home</a> |
		<a xmlns="" href="http://netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="http://www.netkiller.cn/journal/index.html">杂文</a> |
	    <a xmlns="" href="http://www.netkiller.cn/search.html">Search</a> |
	    <a xmlns="" href="http://netkiller-github-com.iteye.com/">ITEYE 博客</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="https://zb.oschina.net/profile/725072/market">作品与服务</a> |
		<a xmlns="" href="mailto:netkiller@msn.com">Email</a><section xml:lang="zh-cn" class="article" id="idm45903520754832"><div class="titlepage"><div><div><h2 class="title">Python Spider 爬虫实例</h2></div><div><div class="author"><h3 class="author"><span class="honorific">Mr</span>. <span class="firstname">Neo Chen</span> <span class="surname">(陈景峯)</span>, <span class="lineage">netkiller, BG7NYT</span></h3><div class="affiliation">
			<div class="address"><p><br/>
				<span class="country">中国</span><span class="state">广东省</span><span class="city">深圳市</span><span class="street">龙华新区民治街道溪山美地</span><br/>
				<span class="postcode">518131</span><br/>
				<span class="phone">+86 13113668890</span><br/>
				<br/>
				<code class="email">&lt;<a class="email" href="mailto:netkiller@msn.com">netkiller@msn.com</a>&gt;</code><br/>
			</p></div>
		</div></div></div><div><div class="legalnotice" id="legalnotice">
	<p class="legalnotice-title"><strong>版权声明</strong></p>
	<p>转载请与作者联系，转载时请务必标明文章原始出处和作者信息及本声明。</p>
	<table style="border: 0; " class="simplelist"><tr><td>
		<a class="ulink" href="http://creativecommons.org/licenses/by/3.0/" target="_top">
			<div><table style="border: 0; width: 180; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/by-nc-sa.png" width="180"/></td></tr></table></div>
		</a>
		</td><td>
			<table style="border: 0; " class="simplelist"><tr><td>
					文档出处:
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.github.io/" target="_top">http://netkiller.github.io</a>
				</td></tr><tr><td>
					<a class="ulink" href="http://netkiller.sourceforge.net/" target="_top">http://netkiller.sourceforge.net</a>
				</td></tr></table>
		</td><td>
			<div><table style="border: 0; width: 80; cellpadding: 0; cellspacing: 0;"><tr><td><img src="/images/weixin.jpg" width="80"/></td></tr></table></div>
		</td><td>
			<p>微信扫描二维码进入 Netkiller 微信订阅号 </p>
			<p>QQ群：128659835 请注明“读者”</p>
		</td></tr></table>
	<p/>
</div></div><div><div class="abstract"><div class="abstract-title">摘要</div>
			<p>.</p>
		</div></div><div><div class="abstract" id="abstract"><div class="abstract-title">我的系列文档</div>
	
	<p>编程语言</p>
	<table style="border: 0; " class="simplelist"><tr><td>
			<a class="ulink" href="../architect/index.html" target="_top">Netkiller Architect 手札</a>
		</td><td>
			<a class="ulink" href="../developer/index.html" target="_top">Netkiller Developer 手札</a>
		</td><td>
			<a class="ulink" href="../php/index.html" target="_top">Netkiller PHP 手札</a>
		</td><td>
			<a class="ulink" href="../python/index.html" target="_top">Netkiller Python 手札</a>
		</td><td>
			<a class="ulink" href="../testing/index.html" target="_top">Netkiller Testing 手札</a>
		</td><td>
			<a class="ulink" href="../cryptography/index.html" target="_top">Netkiller Cryptography 手札</a>
		</td></tr><tr><td>
			<a class="ulink" href="../perl/index.html" target="_top">Netkiller Perl 手札</a>
		</td><td>
			<a class="ulink" href="../docbook/index.html" target="_top">Netkiller Docbook 手札</a>
		</td><td>
			<a class="ulink" href="../project/index.html" target="_top">Netkiller Project 手札</a>
		</td><td>
				<a class="ulink" href="../java/index.html" target="_top">Netkiller Java 手札</a>
			</td><td>
			<a class="ulink" href="../devops/index.html" target="_top">Netkiller DevOps 手札</a>
		</td><td> </td></tr></table>

	<p>操作系统</p>
	<table style="border: 0; " class="simplelist"><tr><td>
			<a class="ulink" href="../linux/index.html" target="_top">Netkiller Linux 手札</a>
		</td><td>
			<a class="ulink" href="../debian/index.html" target="_top">Netkiller Debian 手札</a>
		</td><td>
			<a class="ulink" href="../centos/index.html" target="_top">Netkiller CentOS 手札</a>
		</td><td>
			<a class="ulink" href="../freebsd/index.html" target="_top">Netkiller FreeBSD 手札</a>
		</td><td>
			<a class="ulink" href="../shell/index.html" target="_top">Netkiller Shell 手札</a>
		</td><td>
			<a class="ulink" href="../security/index.html" target="_top">Netkiller Security 手札</a>
		</td></tr><tr><td>
			<a class="ulink" href="../www/index.html" target="_top">Netkiller Web 手札</a>
		</td><td>
			<a class="ulink" href="../monitoring/index.html" target="_top">Netkiller Monitoring 手札</a>
		</td><td>
			<a class="ulink" href="../storage/index.html" target="_top">Netkiller Storage 手札</a>
		</td><td>
			<a class="ulink" href="../mail/index.html" target="_top">Netkiller Mail 手札</a>
		</td><td>
			<a class="ulink" href="../multimedia/index.html" target="_top">Netkiller Multimedia 手札</a>
		</td><td> </td></tr></table>

	<p>数据库</p>
	<table style="border: 0; " class="simplelist"><tr><td>
			<a class="ulink" href="../database/index.html" target="_top">Netkiller Database 手札</a>
		</td><td>
			<a class="ulink" href="../postgresql/index.html" target="_top">Netkiller PostgreSQL 手札</a>
		</td><td>
			<a class="ulink" href="../mysql/index.html" target="_top">Netkiller MySQL 手札</a>
		</td><td>
			<a class="ulink" href="../nosql/index.html" target="_top">Netkiller NoSQL 手札</a>
		</td><td>
			<a class="ulink" href="../ldap/index.html" target="_top">Netkiller LDAP 手札</a>
		</td><td> </td></tr></table>

	<p>网络设备及其他</p>
	<table style="border: 0; " class="simplelist"><tr><td>
			<a class="ulink" href="../network/index.html" target="_top">Netkiller Network 手札</a>
		</td><td>
			<a class="ulink" href="../cisco/index.html" target="_top">Netkiller Cisco IOS 手札</a>
		</td><td>
			<a class="ulink" href="../h3c/index.html" target="_top">Netkiller H3C 手札</a>
		</td><td>
			<a class="ulink" href="../radio/index.html" target="_top">Netkiller Amateur Radio 手札</a>
		</td><td> </td><td> </td></tr></table>

	<p>您可以使用<a class="ulink" href="ibook.epub" target="_top">iBook</a>阅读当前文档</p>

</div></div></div><hr/></div><div class="toc"><div class="toc-title">目录</div><ul class="toc"><li><span class="section"><a href="#idm45903520656208">1. 爬虫实力</a></span></li></ul></div>
	

	<section class="section" id="idm45903520656208"><div class="titlepage"><div><div><h2 class="title" style="clear: both">1. 爬虫实力</h2></div></div></div>
		
		<p>主要的功能是爬出所有URL</p>
		<p>稍加修改可以加入SQL注入检查，跨站脚本攻击检查等等...</p>
		<pre class="screen">
		
#!/usr/bin/env python3
#-*- coding: utf-8 -*-
##############################################
# Home  : http://netkiller.github.com
# Author: Neo &lt;openunix@163.com&gt;
##############################################

##############################################
from multiprocessing import Process
from multiprocessing import Pool
from html.parser import HTMLParser,HTMLParseError
import asyncore, asynchat, socket, threading, queue
import subprocess, os, sys, getopt, configparser, logging
import string, re
import random,time
import urllib.request, urllib.parse, http.client
#from urllib.parse import urlparse

queue = queue.Queue()

class MyHTMLParser(HTMLParser):
	urls 	= []
	def handle_starttag(self, tag, attrs):
		# Only parse the 'anchor' tag.
		if tag == "a":
			# Check the list of defined attributes.
			for name, value in attrs:
				# If href is defined, print it.
				if name == "href":
					#print name, "=", value
					if value and (value.find('javascript') == -1) and (value not in ('#')):
						self.urls.append(value)
	#def handle_endtag(self, tag):
		#print("Encountered  an end tag:", tag)
	#	pass
	#def handle_data(self, data):
		#print("Encountered   some data:", data)
	#	pass
	def gethref(self):
		return self.urls

class Spider():
	logfile = '/tmp/spider.log'
	isdebug = False
	depths = 0
	link	= []
	unlink	= []
	
	referer 	= ''
	useragent 	= 'Neo spider'
	domain		= r''
	baseurl		= r''
	
	skip	= []
	ignore	= []
	
	threadname = ''
	def __init__(self, threadname = None):
		logging.basicConfig(level=logging.NOTSET,
			format='%(asctime)s %(levelname)-8s %(message)s',
			datefmt='%Y-%m-%d %H:%M:%S',
			filename=self.logfile,
			filemode='a')
		self.logging = logging.getLogger()
		if threadname:
			self.threadname = '|'+threadname
	def setDebug(self,isdebug):
		self.isdebug = isdebug
		self.logging.debug('Enable Debug')
	def setDomain(self, tmp):
		if tmp:
			self.domain = tmp
	def setReferer(self,tmp):
		if tmp:
			self.referer = tmp
	def setUseragent(self,tmp):
		if tmp:
			self.useragent = tmp
	def setBaseUrl(self,tmp):
		if tmp:
			self.baseurl = tmp
	def ufilter(self,url):
		if (url not in self.link) :
			self.link.append(url)
		else:
			if url not in self.skip:
				self.skip.append(url)
				self.logging.warning('Skip ' + url)	
			return(None)
		
		if url[0:1] == '/':
			return(self.baseurl + url)
		elif url.find('http://') == -1:
			return(self.baseurl +'/'+ url)
		else:
			if url.find(self.domain) == -1:
				if url not in self.ignore:
					self.logging.warning('Ignore ' + url)
					self.ignore.append(url)
				return(None)

		return(url)

	def working(self, myurl):
		self.depths = self.depths + 1
		if self.depths &gt; 256:
			return()
		#if self.isdebug:
		#	self.logging.debug('&gt;&gt;&gt;' + str(self.depths))
		url = self.ufilter(myurl)
      			
		if url == None:
			return()
		else:
			self.link.append(myurl)
			if self.baseurl:
				urlparse = urllib.parse.urlparse(url)
				self.setBaseUrl(urlparse.scheme+ '://' + urlparse.netloc)
			#self.setDomain(urlparse.netloc)
			#print(urlparse)
			#uri.path
		   	#uri.params
		   	#uri.query
		   	#uri.fragment

		try:
			lines	= []
			parser = MyHTMLParser()
			#html = urllib.request.urlopen(myurl)
			#body = html.read()
			#html.close()
			req = urllib.request.Request(url)
			req.add_header('User-agent', self.useragent)
			req.add_header('Referer', self.referer)
			response = urllib.request.urlopen(req, timeout = 10)
			status 	= response.status
			reason 	= response.reason
			headers = response.info()
			
			log = str(status)+' '+reason+' '+myurl+ ' ('+ str(self.depths)+self.threadname+') '
			
			if self.isdebug:
				#print(response.geturl())
				print(log)
				#print(headers)
			if headers['Content-Type'] in ('text/html'):
				if status == 200:
					body 	= response.read()
					parser.feed(bytes.decode(body))
					lines = parser.gethref()
					self.logging.info(log)
				elif status == 302:
					self.unlink.append(myurl)
					self.logging.critical(log)
				else:
					self.logging.warning(log)

				response.close()
							
				if lines:
					self.referer = random.choice(lines)
					for line in lines:
						#result = re.match ('/http://"(.*)"/"(.*)"', line)
						self.working(line)
						self.depths = self.depths - 1
						#if self.isdebug:
						#	self.logging.debug('&lt;&lt;&lt;' + str(self.depths))
			else:
				self.logging.warning(log + ' ' + headers['Content-Type'])
				response.close()
		except socket.timeout as e:
			self.logging.error(str(e) +' '+ myurl)			
		except urllib.error.URLError as e:
			if self.isdebug:
				print (str(e) +' '+myurl + ' - ' + url) 
			if (e.code == 404):
				self.unlink.append(myurl)
			else:
				print(e.code)
			self.logging.critical(str(e) +' '+ myurl)
		except urllib.error.HTTPError as e:
			self.logging.critical(str(e) +' '+ myurl)		
		except HTMLParseError as e:
			self.logging.error(str(e) +' '+ myurl)
			if self.isdebug:
				print (str(e) +' '+ myurl) 
		except UnicodeDecodeError as e:
			self.logging.critical(str(e) +' '+ myurl)
		except ValueError as e:
			if self.isdebug:
				print (str(e) +' '+ myurl) 			
		#else:
			#self.logging.error(myurl)
		#finally:
			#self.depths = self.depths - 1
			#pass

class ThreadSpider(threading.Thread):
	def __init__(self, queue):
		threading.Thread.__init__(self)
		self.queue = queue

		self.spider = Spider(str(self.name))
		self.spider.setDebug(True)
		
	def run(self):
		while True:
			#grabs host from queue
			host = self.queue.get()
			self.spider.setDomain(host)
			self.spider.working(host)

			#signals to queue job is done
			self.queue.task_done()

def Multithreading():
	workers	= 5
	hosts = ['http://www.example.com/','http://brand.example.com/','http://list.example.com/','http://item.example.com/']
	#spawn a pool of threads, and pass them queue instance 
	for i in range(workers):
		t = ThreadSpider(queue)
		t.setDaemon(True)
		t.start()

	#populate queue with data   
	for host in hosts:
		queue.put(host)

	#wait on the queue until everything has been processed     
	queue.join()

	#p = Pool(processes = 5)
	#p.map(test, [b'http://www.163.com/',b'http://www.sina.com/',b'http://www.qq.com/'])

def test(url):
	spider = Spider()
	spider.setDebug(True)
	spider.working(url)
	print(url)

def daemon(isdaemon):
	if isdaemon :
		pid = os.fork()
		if pid &gt; 0:
			sys.exit(0)
	
def main():
	daemon(isdaemon = False)

	myurl 		= r'http://www.example.com'
	#myurl 		= r'http://www.example.com/mobile.html'
	try:
		start = time.time()
		spider = Spider()
		spider.setDebug(True)
		spider.setDomain('www.example.com')
		spider.setBaseUrl(myurl)
		spider.working(myurl)
		print("Elapsed Time: %s" % (time.time() - start))
	except RuntimeError as e:
		print(e)

if __name__ == '__main__':
	try:
		main()
		#Multithreading()
	except KeyboardInterrupt:
		print ("Crtl+C Pressed. Shutting down.")

		
		</pre>
	</section>
</section><div xmlns="" id="disqus_thread"/><script xmlns="" type="text/javascript">
	        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
	        var disqus_shortname = 'netkiller'; // required: replace example with your forum shortname

	        /* * * DON'T EDIT BELOW THIS LINE * * */
	        (function() {
	            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	        })();
	    </script><noscript xmlns="">Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a xmlns="" href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><br xmlns=""/><a xmlns="" href="http://www.clustrmaps.com/map/Netkiller.cn" title="Visitor Map for Netkiller.cn"><img src="//www.clustrmaps.com/map_v2.png?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"/></a><script xmlns="" type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F997cd4a7320a82d72cb74d179118f697' type='text/javascript'%3E%3C/script%3E"));
</script><script xmlns="" type="text/javascript" src="/js/q.js"/></body></html>